{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db20283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "POLLUTION_JSON_PATH = \"pollution.json\"\n",
    "GREEN_CSV_PATH = \"green_areas.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d99353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation de base\n",
    "\n",
    "def normalize_str(s):\n",
    "    if pd.isna(s):\n",
    "        return None\n",
    "    s = str(s).replace(\"\\xa0\", \" \").strip()\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s.lower()\n",
    "\n",
    "def harmonize_country(cn_norm: str) -> str:\n",
    "    if cn_norm is None:\n",
    "        return None\n",
    "    COUNTRY_MAP = {\n",
    "        # déjà utilisés\n",
    "        \"russian federation\": \"russia\",\n",
    "        \"united states of america\": \"united states\",\n",
    "        \"u.s.a.\": \"united states\",\n",
    "        \"great britain\": \"united kingdom\",\n",
    "        \"uk\": \"united kingdom\",\n",
    "\n",
    "        # ajoutés suite à vos exemples \"ONU\"\n",
    "        \"turkiye\": \"turkey\",\n",
    "        \"iran (islamic republic of)\": \"iran\",\n",
    "        \"syrian arab republic\": \"syria\",\n",
    "        \"lao people's democratic republic\": \"laos\",\n",
    "        \"bolivia (plurinational state of)\": \"bolivia\",\n",
    "        \"venezuela (bolivarian republic of)\": \"venezuela\",\n",
    "        \"tanzania, united republic of\": \"tanzania\",\n",
    "        \"congo, democratic republic of the\": \"democratic republic of the congo\",\n",
    "        \"democratic republic of the congo\": \"democratic republic of the congo\",\n",
    "        \"cote d'ivoire\": \"ivory coast\",\n",
    "        \"cabo verde\": \"cape verde\",\n",
    "        # ajoutez au besoin, mais gardez ça minimal\n",
    "\n",
    "        \"united kingdom of great britain and northern ireland\": \"united kingdom\",\n",
    "        \"republic of korea\": \"south korea\",   # à vérifier selon comment Kaggle le nomme\n",
    "        \"state of palestine\": \"palestine\",\n",
    "    }\n",
    "    return COUNTRY_MAP.get(cn_norm, cn_norm)\n",
    "\n",
    "def strip_parentheses(s: str) -> str:\n",
    "    # \"tiaret (tihert)\" -> \"tiaret\"\n",
    "    return re.sub(r\"\\s*\\(.*?\\)\\s*\", \" \", s).strip()\n",
    "\n",
    "def extract_parentheses(s: str) -> str | None:\n",
    "    # \"kobenhavn (copenhagen)\" -> \"copenhagen\"\n",
    "    m = re.search(r\"\\((.*?)\\)\", s)\n",
    "    if not m:\n",
    "        return None\n",
    "    inside = m.group(1).strip()\n",
    "    # \"nishapur/neyshabur\" -> \"nishapur\" (première variante)\n",
    "    inside = inside.split(\"/\")[0].strip()\n",
    "    return inside if inside else None\n",
    "\n",
    "def strip_after_comma(s: str) -> str:\n",
    "    # \"yulin, guangxi\" -> \"yulin\"\n",
    "    return s.split(\",\")[0].strip()\n",
    "\n",
    "def normalize_city_candidates(city_raw: str) -> list[str]:\n",
    "    \"\"\"Génère plusieurs clés candidates (normalisées) pour maximiser le matching.\"\"\"\n",
    "    if city_raw is None or pd.isna(city_raw):\n",
    "        return []\n",
    "    raw = str(city_raw)\n",
    "    \n",
    "    cand = []\n",
    "\n",
    "    # Candidate principale: normalisation basique\n",
    "    base = normalize_str(raw)\n",
    "    if base:\n",
    "        cand.append(base)\n",
    "\n",
    "    # Avant parenthèses\n",
    "    main = normalize_str(strip_parentheses(raw))\n",
    "    if main and main not in cand:\n",
    "        cand.append(main)\n",
    "\n",
    "    # Dans parenthèses (alias)\n",
    "    inside = extract_parentheses(raw)\n",
    "    if inside:\n",
    "        inside_norm = normalize_str(inside)\n",
    "        if inside_norm and inside_norm not in cand:\n",
    "            cand.append(inside_norm)\n",
    "\n",
    "    # Avant virgule\n",
    "    before_comma = normalize_str(strip_after_comma(raw))\n",
    "    if before_comma and before_comma not in cand:\n",
    "        cand.append(before_comma)\n",
    "\n",
    "    # Optionnel : enlever les tirets (parfois Kaggle a \"san pedro sula\" vs \"san-pedro-sula\")\n",
    "    dehyphen = normalize_str(raw.replace(\"-\", \" \"))\n",
    "    if dehyphen and dehyphen not in cand:\n",
    "        cand.append(dehyphen)\n",
    "\n",
    "    return cand\n",
    "\n",
    "def to_float(x):\n",
    "    \"\"\"Gère '  5.49 ' et aussi des virgules européennes '5,49'.\"\"\"\n",
    "    if pd.isna(x):\n",
    "        return pd.NA\n",
    "    s = str(x).strip().replace(\"\\xa0\", \" \")\n",
    "    s = s.replace(\",\", \".\")\n",
    "    s = re.sub(r\"\\s+\", \"\", s)\n",
    "    if s == \"\":\n",
    "        return pd.NA\n",
    "    return pd.to_numeric(s, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13fb5e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pollution pairs: 23035\n"
     ]
    }
   ],
   "source": [
    "# Charger pollution set\n",
    "\n",
    "with open(POLLUTION_JSON_PATH, encoding=\"utf-8\") as f:\n",
    "    pollution = json.load(f)\n",
    "\n",
    "df_poll = pd.json_normalize(pollution[\"measurements\"])\n",
    "df_poll[\"country_join\"] = df_poll[\"country_name\"].apply(normalize_str).apply(harmonize_country)\n",
    "df_poll[\"city_join\"] = df_poll[\"city_name\"].apply(normalize_str)\n",
    "\n",
    "poll_pairs = set(zip(df_poll[\"country_join\"], df_poll[\"city_join\"]))\n",
    "\n",
    "print(\"Pollution pairs:\", len(poll_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d7136ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger green\n",
    "\n",
    "df_green = pd.read_csv(GREEN_CSV_PATH, encoding=\"utf-8-sig\")\n",
    "\n",
    "col_country = \"Country or Territory Name\"\n",
    "col_citycode = \"City Code\"\n",
    "col_cityname = \"City Name\"\n",
    "col_share2020 = \"Average share of green area in city/ urban area 2020 (%)\"\n",
    "col_percap2020 = \"Green area per capita 2020 (m2/person)\"\n",
    "\n",
    "# Drop lignes incomplètes city name / code\n",
    "df_green[col_cityname] = df_green[col_cityname].replace(r\"^\\s*$\", pd.NA, regex=True)\n",
    "df_green[col_citycode] = df_green[col_citycode].replace(r\"^\\s*$\", pd.NA, regex=True)\n",
    "df_green = df_green.dropna(subset=[col_cityname, col_citycode]).copy()\n",
    "\n",
    "# Normaliser pays\n",
    "df_green[\"country_join\"] = df_green[col_country].apply(normalize_str).apply(harmonize_country)\n",
    "\n",
    "# Construire une clé ville choisie \"best match\"\n",
    "def choose_best_city_join(row):\n",
    "    ctry = row[\"country_join\"]\n",
    "    candidates = normalize_city_candidates(row[col_cityname])\n",
    "    for cand in candidates:\n",
    "        if (ctry, cand) in poll_pairs:\n",
    "            return cand\n",
    "    # fallback : meilleure candidate \"main\" (sans parenthèses) sinon base\n",
    "    return candidates[1] if len(candidates) > 1 else (candidates[0] if candidates else None)\n",
    "\n",
    "df_green[\"city_join\"] = df_green.apply(choose_best_city_join, axis=1)\n",
    "\n",
    "# Convertir numeric 2020 (facultatif mais pratique)\n",
    "df_green[\"green_share_2020\"] = df_green[col_share2020].apply(to_float)\n",
    "df_green[\"green_m2_per_capita_2020\"] = df_green[col_percap2020].apply(to_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6774d30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green pairs (after drop NA) : 659\n",
      "Common after improvements  : 450\n",
      "Exemples green NON trouvés (après): [('nicaragua', 'leon'), ('iraq', 'diwaniyah'), ('eswatini', 'mbabane'), ('australia', 'bunbury'), ('ireland', 'dublin'), ('iraq', 'amara'), ('chile', 'los angeles'), ('mexico', 'campeche_campeche'), ('chile', 'santiago'), ('pakistan', 'sheikhupura'), ('russia', 'moskva'), ('united states', 'toledo'), ('south korea', 'jeju'), ('canada', 'ottawa gatineau'), ('palestine', 'nabulus'), ('egypt', 'az zaqazig'), ('mexico', 'merida'), ('morocco', 'sidi slimane'), ('iran', 'bandar abbas'), ('philippines', 'davao city')]\n"
     ]
    }
   ],
   "source": [
    "# Stats avant / après\n",
    "\n",
    "green_pairs_after = set(zip(df_green[\"country_join\"], df_green[\"city_join\"]))\n",
    "common_after = green_pairs_after & poll_pairs\n",
    "\n",
    "print(\"Green pairs (after drop NA) :\", len(green_pairs_after))\n",
    "print(\"Common after improvements  :\", len(common_after))\n",
    "\n",
    "# Exemples non matchés (après)\n",
    "only_green = list(green_pairs_after - poll_pairs)[:20]\n",
    "print(\"Exemples green NON trouvés (après):\", only_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8659327f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: green_areas_cleaned.csv\n",
      "['south korea']\n"
     ]
    }
   ],
   "source": [
    "# Export facelift (sans FootNote/Data Source par défaut)\n",
    "\n",
    "out_cols = [\n",
    "    col_country, col_citycode, col_cityname,\n",
    "    \"country_join\", \"city_join\",\n",
    "    \"green_share_2020\", \"green_m2_per_capita_2020\"\n",
    "]\n",
    "df_green[out_cols].to_csv(\"green_areas_cleaned.csv\", index=False, encoding=\"utf-8\")\n",
    "print(\"Wrote: green_areas_cleaned.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
